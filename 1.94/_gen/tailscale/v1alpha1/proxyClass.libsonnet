{
  local d = (import 'doc-util/main.libsonnet'),
  '#':: d.pkg(name='proxyClass', url='', help='"ProxyClass describes a set of configuration parameters that can be applied to\\nproxy resources created by the Tailscale Kubernetes operator.\\nTo apply a given ProxyClass to resources created for a tailscale Ingress or\\nService, use tailscale.com/proxy-class=<proxyclass-name> label. To apply a\\ngiven ProxyClass to resources created for a Connector, use\\nconnector.spec.proxyClass field.\\nProxyClass is a cluster scoped resource.\\nMore info:\\nhttps://tailscale.com/kb/1445/kubernetes-operator-customization#cluster-resource-customization-using-proxyclass-custom-resource"'),
  '#metadata':: d.obj(help='"ObjectMeta is metadata that all persisted resources must have, which includes all objects users must create."'),
  metadata: {
    '#withAnnotations':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotations(annotations): { metadata+: { annotations: annotations } },
    '#withAnnotationsMixin':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotationsMixin(annotations): { metadata+: { annotations+: annotations } },
    '#withClusterName':: d.fn(help='"The name of the cluster which the object belongs to. This is used to distinguish resources with same name and namespace in different clusters. This field is not set anywhere right now and apiserver is going to ignore it if set in create or update request."', args=[d.arg(name='clusterName', type=d.T.string)]),
    withClusterName(clusterName): { metadata+: { clusterName: clusterName } },
    '#withCreationTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='creationTimestamp', type=d.T.string)]),
    withCreationTimestamp(creationTimestamp): { metadata+: { creationTimestamp: creationTimestamp } },
    '#withDeletionGracePeriodSeconds':: d.fn(help='"Number of seconds allowed for this object to gracefully terminate before it will be removed from the system. Only set when deletionTimestamp is also set. May only be shortened. Read-only."', args=[d.arg(name='deletionGracePeriodSeconds', type=d.T.integer)]),
    withDeletionGracePeriodSeconds(deletionGracePeriodSeconds): { metadata+: { deletionGracePeriodSeconds: deletionGracePeriodSeconds } },
    '#withDeletionTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='deletionTimestamp', type=d.T.string)]),
    withDeletionTimestamp(deletionTimestamp): { metadata+: { deletionTimestamp: deletionTimestamp } },
    '#withFinalizers':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizers(finalizers): { metadata+: { finalizers: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withFinalizersMixin':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizersMixin(finalizers): { metadata+: { finalizers+: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withGenerateName':: d.fn(help='"GenerateName is an optional prefix, used by the server, to generate a unique name ONLY IF the Name field has not been provided. If this field is used, the name returned to the client will be different than the name passed. This value will also be combined with a unique suffix. The provided value has the same validation rules as the Name field, and may be truncated by the length of the suffix required to make the value unique on the server.\\n\\nIf this field is specified and the generated name exists, the server will NOT return a 409 - instead, it will either return 201 Created or 500 with Reason ServerTimeout indicating a unique name could not be found in the time allotted, and the client should retry (optionally after the time indicated in the Retry-After header).\\n\\nApplied only if Name is not specified. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency"', args=[d.arg(name='generateName', type=d.T.string)]),
    withGenerateName(generateName): { metadata+: { generateName: generateName } },
    '#withGeneration':: d.fn(help='"A sequence number representing a specific generation of the desired state. Populated by the system. Read-only."', args=[d.arg(name='generation', type=d.T.integer)]),
    withGeneration(generation): { metadata+: { generation: generation } },
    '#withLabels':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"', args=[d.arg(name='labels', type=d.T.object)]),
    withLabels(labels): { metadata+: { labels: labels } },
    '#withLabelsMixin':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
    withLabelsMixin(labels): { metadata+: { labels+: labels } },
    '#withName':: d.fn(help='"Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names"', args=[d.arg(name='name', type=d.T.string)]),
    withName(name): { metadata+: { name: name } },
    '#withNamespace':: d.fn(help='"Namespace defines the space within which each name must be unique. An empty namespace is equivalent to the \\"default\\" namespace, but \\"default\\" is the canonical representation. Not all objects are required to be scoped to a namespace - the value of this field for those objects will be empty.\\n\\nMust be a DNS_LABEL. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/namespaces"', args=[d.arg(name='namespace', type=d.T.string)]),
    withNamespace(namespace): { metadata+: { namespace: namespace } },
    '#withOwnerReferences':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferences(ownerReferences): { metadata+: { ownerReferences: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withOwnerReferencesMixin':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferencesMixin(ownerReferences): { metadata+: { ownerReferences+: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withResourceVersion':: d.fn(help='"An opaque value that represents the internal version of this object that can be used by clients to determine when objects have changed. May be used for optimistic concurrency, change detection, and the watch operation on a resource or set of resources. Clients must treat these values as opaque and passed unmodified back to the server. They may only be valid for a particular resource or set of resources.\\n\\nPopulated by the system. Read-only. Value must be treated as opaque by clients and . More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency"', args=[d.arg(name='resourceVersion', type=d.T.string)]),
    withResourceVersion(resourceVersion): { metadata+: { resourceVersion: resourceVersion } },
    '#withSelfLink':: d.fn(help='"SelfLink is a URL representing this object. Populated by the system. Read-only.\\n\\nDEPRECATED Kubernetes will stop propagating this field in 1.20 release and the field is planned to be removed in 1.21 release."', args=[d.arg(name='selfLink', type=d.T.string)]),
    withSelfLink(selfLink): { metadata+: { selfLink: selfLink } },
    '#withUid':: d.fn(help='"UID is the unique in time and space value for this object. It is typically generated by the server on successful creation of a resource and is not allowed to change on PUT operations.\\n\\nPopulated by the system. Read-only. More info: http://kubernetes.io/docs/user-guide/identifiers#uids"', args=[d.arg(name='uid', type=d.T.string)]),
    withUid(uid): { metadata+: { uid: uid } },
  },
  '#new':: d.fn(help='new returns an instance of ProxyClass', args=[d.arg(name='name', type=d.T.string)]),
  new(name): {
    apiVersion: 'tailscale.com/v1alpha1',
    kind: 'ProxyClass',
  } + self.metadata.withName(name=name) + self.metadata.withAnnotations(annotations={
    'tanka.dev/namespaced': 'false',
  }),
  '#spec':: d.obj(help='"Specification of the desired state of the ProxyClass resource.\\nhttps://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#spec-and-status"'),
  spec: {
    '#metrics':: d.obj(help='"Configuration for proxy metrics. Metrics are currently not supported\\nfor egress proxies and for Ingress proxies that have been configured\\nwith tailscale.com/experimental-forward-cluster-traffic-via-ingress\\nannotation. Note that the metrics are currently considered unstable\\nand will likely change in breaking ways in the future - we only\\nrecommend that you use those for debugging purposes."'),
    metrics: {
      '#serviceMonitor':: d.obj(help="\"Enable to create a Prometheus ServiceMonitor for scraping the proxy's Tailscale metrics.\\nThe ServiceMonitor will select the metrics Service that gets created when metrics are enabled.\\nThe ingested metrics for each Service monitor will have labels to identify the proxy:\\nts_proxy_type: ingress_service|ingress_resource|connector|proxygroup\\nts_proxy_parent_name: name of the parent resource (i.e name of the Connector, Tailscale Ingress, Tailscale Service or ProxyGroup)\\nts_proxy_parent_namespace: namespace of the parent resource (if the parent resource is not cluster scoped)\\njob: ts_\u003cproxy type\u003e_[\u003cparent namespace\u003e]_\u003cparent_name\u003e\""),
      serviceMonitor: {
        '#withEnable':: d.fn(help='"If Enable is set to true, a Prometheus ServiceMonitor will be created. Enable can only be set to true if metrics are enabled."', args=[d.arg(name='enable', type=d.T.boolean)]),
        withEnable(enable): { spec+: { metrics+: { serviceMonitor+: { enable: enable } } } },
        '#withLabels':: d.fn(help='"Labels to add to the ServiceMonitor.\\nLabels must be valid Kubernetes labels.\\nhttps://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#syntax-and-character-set"', args=[d.arg(name='labels', type=d.T.object)]),
        withLabels(labels): { spec+: { metrics+: { serviceMonitor+: { labels: labels } } } },
        '#withLabelsMixin':: d.fn(help='"Labels to add to the ServiceMonitor.\\nLabels must be valid Kubernetes labels.\\nhttps://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#syntax-and-character-set"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
        withLabelsMixin(labels): { spec+: { metrics+: { serviceMonitor+: { labels+: labels } } } },
      },
      '#withEnable':: d.fn(help="\"Setting enable to true will make the proxy serve Tailscale metrics\\nat \u003cpod-ip\u003e:9002/metrics.\\nA metrics Service named \u003cproxy-statefulset\u003e-metrics will also be created in the operator's namespace and will\\nserve the metrics at \u003cservice-ip\u003e:9002/metrics.\\n\\nIn 1.78.x and 1.80.x, this field also serves as the default value for\\n.spec.statefulSet.pod.tailscaleContainer.debug.enable. From 1.82.0, both\\nfields will independently default to false.\\n\\nDefaults to false.\"", args=[d.arg(name='enable', type=d.T.boolean)]),
      withEnable(enable): { spec+: { metrics+: { enable: enable } } },
    },
    '#statefulSet':: d.obj(help="\"Configuration parameters for the proxy's StatefulSet. Tailscale\\nKubernetes operator deploys a StatefulSet for each of the user\\nconfigured proxies (Tailscale Ingress, Tailscale Service, Connector).\""),
    statefulSet: {
      '#pod':: d.obj(help='"Configuration for the proxy Pod."'),
      pod: {
        '#affinity':: d.obj(help="\"Proxy Pod's affinity rules.\\nBy default, the Tailscale Kubernetes operator does not apply any affinity rules.\\nhttps://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#affinity\""),
        affinity: {
          '#nodeAffinity':: d.obj(help='"Describes node affinity scheduling rules for the pod."'),
          nodeAffinity: {
            '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."'),
            preferredDuringSchedulingIgnoredDuringExecution: {
              '#preference':: d.obj(help='"A node selector term, associated with the corresponding weight."'),
              preference: {
                '#matchExpressions':: d.obj(help="\"A list of node selector requirements by node's labels.\""),
                matchExpressions: {
                  '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#matchFields':: d.obj(help="\"A list of node selector requirements by node's fields.\""),
                matchFields: {
                  '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help="\"A list of node selector requirements by node's labels.\"", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { preference+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchExpressionsMixin':: d.fn(help="\"A list of node selector requirements by node's labels.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { preference+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchFields':: d.fn(help="\"A list of node selector requirements by node's fields.\"", args=[d.arg(name='matchFields', type=d.T.array)]),
                withMatchFields(matchFields): { preference+: { matchFields: if std.isArray(v=matchFields) then matchFields else [matchFields] } },
                '#withMatchFieldsMixin':: d.fn(help="\"A list of node selector requirements by node's fields.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchFields', type=d.T.array)]),
                withMatchFieldsMixin(matchFields): { preference+: { matchFields+: if std.isArray(v=matchFields) then matchFields else [matchFields] } },
              },
              '#withWeight':: d.fn(help='"Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
              withWeight(weight): { weight: weight },
            },
            '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to an update), the system\\nmay or may not try to eventually evict the pod from its node."'),
            requiredDuringSchedulingIgnoredDuringExecution: {
              '#nodeSelectorTerms':: d.obj(help='"Required. A list of node selector terms. The terms are ORed."'),
              nodeSelectorTerms: {
                '#matchExpressions':: d.obj(help="\"A list of node selector requirements by node's labels.\""),
                matchExpressions: {
                  '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#matchFields':: d.obj(help="\"A list of node selector requirements by node's fields.\""),
                matchFields: {
                  '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help="\"A list of node selector requirements by node's labels.\"", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] },
                '#withMatchExpressionsMixin':: d.fn(help="\"A list of node selector requirements by node's labels.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] },
                '#withMatchFields':: d.fn(help="\"A list of node selector requirements by node's fields.\"", args=[d.arg(name='matchFields', type=d.T.array)]),
                withMatchFields(matchFields): { matchFields: if std.isArray(v=matchFields) then matchFields else [matchFields] },
                '#withMatchFieldsMixin':: d.fn(help="\"A list of node selector requirements by node's fields.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchFields', type=d.T.array)]),
                withMatchFieldsMixin(matchFields): { matchFields+: if std.isArray(v=matchFields) then matchFields else [matchFields] },
              },
              '#withNodeSelectorTerms':: d.fn(help='"Required. A list of node selector terms. The terms are ORed."', args=[d.arg(name='nodeSelectorTerms', type=d.T.array)]),
              withNodeSelectorTerms(nodeSelectorTerms): { spec+: { statefulSet+: { pod+: { affinity+: { nodeAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: { nodeSelectorTerms: if std.isArray(v=nodeSelectorTerms) then nodeSelectorTerms else [nodeSelectorTerms] } } } } } } },
              '#withNodeSelectorTermsMixin':: d.fn(help='"Required. A list of node selector terms. The terms are ORed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodeSelectorTerms', type=d.T.array)]),
              withNodeSelectorTermsMixin(nodeSelectorTerms): { spec+: { statefulSet+: { pod+: { affinity+: { nodeAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: { nodeSelectorTerms+: if std.isArray(v=nodeSelectorTerms) then nodeSelectorTerms else [nodeSelectorTerms] } } } } } } },
            },
            '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { statefulSet+: { pod+: { affinity+: { nodeAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { statefulSet+: { pod+: { affinity+: { nodeAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } },
          },
          '#podAffinity':: d.obj(help='"Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s))."'),
          podAffinity: {
            '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."'),
            preferredDuringSchedulingIgnoredDuringExecution: {
              '#podAffinityTerm':: d.obj(help='"Required. A pod affinity term, associated with the corresponding weight."'),
              podAffinityTerm: {
                '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                labelSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels: matchLabels } } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels+: matchLabels } } },
                },
                '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                namespaceSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels: matchLabels } } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels+: matchLabels } } },
                },
                '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeys(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeysMixin(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeys(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeysMixin(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespaces(namespaces): { podAffinityTerm+: { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespacesMixin(namespaces): { podAffinityTerm+: { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                withTopologyKey(topologyKey): { podAffinityTerm+: { topologyKey: topologyKey } },
              },
              '#withWeight':: d.fn(help='"weight associated with matching the corresponding podAffinityTerm,\\nin the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
              withWeight(weight): { weight: weight },
            },
            '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."'),
            requiredDuringSchedulingIgnoredDuringExecution: {
              '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
              labelSelector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { labelSelector+: { matchLabels: matchLabels } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { labelSelector+: { matchLabels+: matchLabels } },
              },
              '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
              namespaceSelector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { namespaceSelector+: { matchLabels: matchLabels } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { namespaceSelector+: { matchLabels+: matchLabels } },
              },
              '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
              withMatchLabelKeys(matchLabelKeys): { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
              '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
              withMatchLabelKeysMixin(matchLabelKeys): { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
              '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
              withMismatchLabelKeys(mismatchLabelKeys): { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
              '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
              withMismatchLabelKeysMixin(mismatchLabelKeys): { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
              '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
              withNamespaces(namespaces): { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] },
              '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
              withNamespacesMixin(namespaces): { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] },
              '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
              withTopologyKey(topologyKey): { topologyKey: topologyKey },
            },
            '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { statefulSet+: { pod+: { affinity+: { podAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { statefulSet+: { pod+: { affinity+: { podAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withRequiredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withRequiredDuringSchedulingIgnoredDuringExecution(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { statefulSet+: { pod+: { affinity+: { podAffinity+: { requiredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withRequiredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withRequiredDuringSchedulingIgnoredDuringExecutionMixin(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { statefulSet+: { pod+: { affinity+: { podAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } },
          },
          '#podAntiAffinity':: d.obj(help='"Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s))."'),
          podAntiAffinity: {
            '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and subtracting\\n\\"weight\\" from the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."'),
            preferredDuringSchedulingIgnoredDuringExecution: {
              '#podAffinityTerm':: d.obj(help='"Required. A pod affinity term, associated with the corresponding weight."'),
              podAffinityTerm: {
                '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                labelSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels: matchLabels } } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels+: matchLabels } } },
                },
                '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                namespaceSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels: matchLabels } } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels+: matchLabels } } },
                },
                '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeys(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeysMixin(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeys(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeysMixin(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespaces(namespaces): { podAffinityTerm+: { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespacesMixin(namespaces): { podAffinityTerm+: { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                withTopologyKey(topologyKey): { podAffinityTerm+: { topologyKey: topologyKey } },
              },
              '#withWeight':: d.fn(help='"weight associated with matching the corresponding podAffinityTerm,\\nin the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
              withWeight(weight): { weight: weight },
            },
            '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."'),
            requiredDuringSchedulingIgnoredDuringExecution: {
              '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
              labelSelector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { labelSelector+: { matchLabels: matchLabels } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { labelSelector+: { matchLabels+: matchLabels } },
              },
              '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
              namespaceSelector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { namespaceSelector+: { matchLabels: matchLabels } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { namespaceSelector+: { matchLabels+: matchLabels } },
              },
              '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
              withMatchLabelKeys(matchLabelKeys): { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
              '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
              withMatchLabelKeysMixin(matchLabelKeys): { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
              '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
              withMismatchLabelKeys(mismatchLabelKeys): { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
              '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
              withMismatchLabelKeysMixin(mismatchLabelKeys): { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
              '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
              withNamespaces(namespaces): { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] },
              '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
              withNamespacesMixin(namespaces): { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] },
              '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
              withTopologyKey(topologyKey): { topologyKey: topologyKey },
            },
            '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and subtracting\\n\\"weight\\" from the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { statefulSet+: { pod+: { affinity+: { podAntiAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and subtracting\\n\\"weight\\" from the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { statefulSet+: { pod+: { affinity+: { podAntiAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withRequiredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withRequiredDuringSchedulingIgnoredDuringExecution(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { statefulSet+: { pod+: { affinity+: { podAntiAffinity+: { requiredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withRequiredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withRequiredDuringSchedulingIgnoredDuringExecutionMixin(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { statefulSet+: { pod+: { affinity+: { podAntiAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } },
          },
        },
        '#dnsConfig':: d.obj(help='"DNSConfig defines DNS parameters for the proxy Pod in addition to those generated from DNSPolicy.\\nWhen DNSPolicy is set to \\"None\\", DNSConfig must be specified.\\nhttps://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-dns-config"'),
        dnsConfig: {
          '#options':: d.obj(help='"A list of DNS resolver options.\\nThis will be merged with the base options generated from DNSPolicy.\\nDuplicated entries will be removed. Resolution options given in Options\\nwill override those that appear in the base DNSPolicy."'),
          options: {
            '#withName':: d.fn(help="\"Name is this DNS resolver option's name.\\nRequired.\"", args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withValue':: d.fn(help="\"Value is this DNS resolver option's value.\"", args=[d.arg(name='value', type=d.T.string)]),
            withValue(value): { value: value },
          },
          '#withNameservers':: d.fn(help='"A list of DNS name server IP addresses.\\nThis will be appended to the base nameservers generated from DNSPolicy.\\nDuplicated nameservers will be removed."', args=[d.arg(name='nameservers', type=d.T.array)]),
          withNameservers(nameservers): { spec+: { statefulSet+: { pod+: { dnsConfig+: { nameservers: if std.isArray(v=nameservers) then nameservers else [nameservers] } } } } },
          '#withNameserversMixin':: d.fn(help='"A list of DNS name server IP addresses.\\nThis will be appended to the base nameservers generated from DNSPolicy.\\nDuplicated nameservers will be removed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nameservers', type=d.T.array)]),
          withNameserversMixin(nameservers): { spec+: { statefulSet+: { pod+: { dnsConfig+: { nameservers+: if std.isArray(v=nameservers) then nameservers else [nameservers] } } } } },
          '#withOptions':: d.fn(help='"A list of DNS resolver options.\\nThis will be merged with the base options generated from DNSPolicy.\\nDuplicated entries will be removed. Resolution options given in Options\\nwill override those that appear in the base DNSPolicy."', args=[d.arg(name='options', type=d.T.array)]),
          withOptions(options): { spec+: { statefulSet+: { pod+: { dnsConfig+: { options: if std.isArray(v=options) then options else [options] } } } } },
          '#withOptionsMixin':: d.fn(help='"A list of DNS resolver options.\\nThis will be merged with the base options generated from DNSPolicy.\\nDuplicated entries will be removed. Resolution options given in Options\\nwill override those that appear in the base DNSPolicy."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='options', type=d.T.array)]),
          withOptionsMixin(options): { spec+: { statefulSet+: { pod+: { dnsConfig+: { options+: if std.isArray(v=options) then options else [options] } } } } },
          '#withSearches':: d.fn(help='"A list of DNS search domains for host-name lookup.\\nThis will be appended to the base search paths generated from DNSPolicy.\\nDuplicated search paths will be removed."', args=[d.arg(name='searches', type=d.T.array)]),
          withSearches(searches): { spec+: { statefulSet+: { pod+: { dnsConfig+: { searches: if std.isArray(v=searches) then searches else [searches] } } } } },
          '#withSearchesMixin':: d.fn(help='"A list of DNS search domains for host-name lookup.\\nThis will be appended to the base search paths generated from DNSPolicy.\\nDuplicated search paths will be removed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='searches', type=d.T.array)]),
          withSearchesMixin(searches): { spec+: { statefulSet+: { pod+: { dnsConfig+: { searches+: if std.isArray(v=searches) then searches else [searches] } } } } },
        },
        '#imagePullSecrets':: d.obj(help="\"Proxy Pod's image pull Secrets.\\nhttps://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#PodSpec\""),
        imagePullSecrets: {
          '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
        },
        '#securityContext':: d.obj(help="\"Proxy Pod's security context.\\nBy default Tailscale Kubernetes operator does not apply any Pod\\nsecurity context.\\nhttps://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#security-context-2\""),
        securityContext: {
          '#appArmorProfile':: d.obj(help='"appArmorProfile is the AppArmor options to use by the containers in this pod.\\nNote that this field cannot be set when spec.os.name is windows."'),
          appArmorProfile: {
            '#withLocalhostProfile':: d.fn(help='"localhostProfile indicates a profile loaded on the node that should be used.\\nThe profile must be preconfigured on the node to work.\\nMust match the loaded name of the profile.\\nMust be set if and only if type is \\"Localhost\\"."', args=[d.arg(name='localhostProfile', type=d.T.string)]),
            withLocalhostProfile(localhostProfile): { spec+: { statefulSet+: { pod+: { securityContext+: { appArmorProfile+: { localhostProfile: localhostProfile } } } } } },
            '#withType':: d.fn(help="\"type indicates which kind of AppArmor profile will be applied.\\nValid options are:\\n  Localhost - a profile pre-loaded on the node.\\n  RuntimeDefault - the container runtime's default profile.\\n  Unconfined - no AppArmor enforcement.\"", args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { spec+: { statefulSet+: { pod+: { securityContext+: { appArmorProfile+: { type: type } } } } } },
          },
          '#seLinuxOptions':: d.obj(help='"The SELinux context to be applied to all containers.\\nIf unspecified, the container runtime will allocate a random SELinux context for each\\ncontainer.  May also be set in SecurityContext.  If set in\\nboth SecurityContext and PodSecurityContext, the value specified in SecurityContext\\ntakes precedence for that container.\\nNote that this field cannot be set when spec.os.name is windows."'),
          seLinuxOptions: {
            '#withLevel':: d.fn(help='"Level is SELinux level label that applies to the container."', args=[d.arg(name='level', type=d.T.string)]),
            withLevel(level): { spec+: { statefulSet+: { pod+: { securityContext+: { seLinuxOptions+: { level: level } } } } } },
            '#withRole':: d.fn(help='"Role is a SELinux role label that applies to the container."', args=[d.arg(name='role', type=d.T.string)]),
            withRole(role): { spec+: { statefulSet+: { pod+: { securityContext+: { seLinuxOptions+: { role: role } } } } } },
            '#withType':: d.fn(help='"Type is a SELinux type label that applies to the container."', args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { spec+: { statefulSet+: { pod+: { securityContext+: { seLinuxOptions+: { type: type } } } } } },
            '#withUser':: d.fn(help='"User is a SELinux user label that applies to the container."', args=[d.arg(name='user', type=d.T.string)]),
            withUser(user): { spec+: { statefulSet+: { pod+: { securityContext+: { seLinuxOptions+: { user: user } } } } } },
          },
          '#seccompProfile':: d.obj(help='"The seccomp options to use by the containers in this pod.\\nNote that this field cannot be set when spec.os.name is windows."'),
          seccompProfile: {
            '#withLocalhostProfile':: d.fn(help="\"localhostProfile indicates a profile defined in a file on the node should be used.\\nThe profile must be preconfigured on the node to work.\\nMust be a descending path, relative to the kubelet's configured seccomp profile location.\\nMust be set if type is \\\"Localhost\\\". Must NOT be set for any other type.\"", args=[d.arg(name='localhostProfile', type=d.T.string)]),
            withLocalhostProfile(localhostProfile): { spec+: { statefulSet+: { pod+: { securityContext+: { seccompProfile+: { localhostProfile: localhostProfile } } } } } },
            '#withType':: d.fn(help='"type indicates which kind of seccomp profile will be applied.\\nValid options are:\\n\\nLocalhost - a profile defined in a file on the node should be used.\\nRuntimeDefault - the container runtime default profile should be used.\\nUnconfined - no profile should be applied."', args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { spec+: { statefulSet+: { pod+: { securityContext+: { seccompProfile+: { type: type } } } } } },
          },
          '#sysctls':: d.obj(help='"Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported\\nsysctls (by the container runtime) might fail to launch.\\nNote that this field cannot be set when spec.os.name is windows."'),
          sysctls: {
            '#withName':: d.fn(help='"Name of a property to set"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withValue':: d.fn(help='"Value of a property to set"', args=[d.arg(name='value', type=d.T.string)]),
            withValue(value): { value: value },
          },
          '#windowsOptions':: d.obj(help="\"The Windows specific settings applied to all containers.\\nIf unspecified, the options within a container's SecurityContext will be used.\\nIf set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is linux.\""),
          windowsOptions: {
            '#withGmsaCredentialSpec':: d.fn(help='"GMSACredentialSpec is where the GMSA admission webhook\\n(https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the\\nGMSA credential spec named by the GMSACredentialSpecName field."', args=[d.arg(name='gmsaCredentialSpec', type=d.T.string)]),
            withGmsaCredentialSpec(gmsaCredentialSpec): { spec+: { statefulSet+: { pod+: { securityContext+: { windowsOptions+: { gmsaCredentialSpec: gmsaCredentialSpec } } } } } },
            '#withGmsaCredentialSpecName':: d.fn(help='"GMSACredentialSpecName is the name of the GMSA credential spec to use."', args=[d.arg(name='gmsaCredentialSpecName', type=d.T.string)]),
            withGmsaCredentialSpecName(gmsaCredentialSpecName): { spec+: { statefulSet+: { pod+: { securityContext+: { windowsOptions+: { gmsaCredentialSpecName: gmsaCredentialSpecName } } } } } },
            '#withHostProcess':: d.fn(help="\"HostProcess determines if a container should be run as a 'Host Process' container.\\nAll of a Pod's containers must have the same effective HostProcess value\\n(it is not allowed to have a mix of HostProcess containers and non-HostProcess containers).\\nIn addition, if HostProcess is true then HostNetwork must also be set to true.\"", args=[d.arg(name='hostProcess', type=d.T.boolean)]),
            withHostProcess(hostProcess): { spec+: { statefulSet+: { pod+: { securityContext+: { windowsOptions+: { hostProcess: hostProcess } } } } } },
            '#withRunAsUserName':: d.fn(help='"The UserName in Windows to run the entrypoint of the container process.\\nDefaults to the user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext. If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsUserName', type=d.T.string)]),
            withRunAsUserName(runAsUserName): { spec+: { statefulSet+: { pod+: { securityContext+: { windowsOptions+: { runAsUserName: runAsUserName } } } } } },
          },
          '#withFsGroup':: d.fn(help="\"A special supplemental group that applies to all containers in a pod.\\nSome volume types allow the Kubelet to change the ownership of that volume\\nto be owned by the pod:\\n\\n1. The owning GID will be the FSGroup\\n2. The setgid bit is set (new files created in the volume will be owned by FSGroup)\\n3. The permission bits are OR'd with rw-rw----\\n\\nIf unset, the Kubelet will not modify the ownership and permissions of any volume.\\nNote that this field cannot be set when spec.os.name is windows.\"", args=[d.arg(name='fsGroup', type=d.T.integer)]),
          withFsGroup(fsGroup): { spec+: { statefulSet+: { pod+: { securityContext+: { fsGroup: fsGroup } } } } },
          '#withFsGroupChangePolicy':: d.fn(help='"fsGroupChangePolicy defines behavior of changing ownership and permission of the volume\\nbefore being exposed inside Pod. This field will only apply to\\nvolume types which support fsGroup based ownership(and permissions).\\nIt will have no effect on ephemeral volume types such as: secret, configmaps\\nand emptydir.\\nValid values are \\"OnRootMismatch\\" and \\"Always\\". If not specified, \\"Always\\" is used.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='fsGroupChangePolicy', type=d.T.string)]),
          withFsGroupChangePolicy(fsGroupChangePolicy): { spec+: { statefulSet+: { pod+: { securityContext+: { fsGroupChangePolicy: fsGroupChangePolicy } } } } },
          '#withRunAsGroup':: d.fn(help='"The GID to run the entrypoint of the container process.\\nUses runtime default if unset.\\nMay also be set in SecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence\\nfor that container.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsGroup', type=d.T.integer)]),
          withRunAsGroup(runAsGroup): { spec+: { statefulSet+: { pod+: { securityContext+: { runAsGroup: runAsGroup } } } } },
          '#withRunAsNonRoot':: d.fn(help='"Indicates that the container must run as a non-root user.\\nIf true, the Kubelet will validate the image at runtime to ensure that it\\ndoes not run as UID 0 (root) and fail to start the container if it does.\\nIf unset or false, no such validation will be performed.\\nMay also be set in SecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsNonRoot', type=d.T.boolean)]),
          withRunAsNonRoot(runAsNonRoot): { spec+: { statefulSet+: { pod+: { securityContext+: { runAsNonRoot: runAsNonRoot } } } } },
          '#withRunAsUser':: d.fn(help='"The UID to run the entrypoint of the container process.\\nDefaults to user specified in image metadata if unspecified.\\nMay also be set in SecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence\\nfor that container.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsUser', type=d.T.integer)]),
          withRunAsUser(runAsUser): { spec+: { statefulSet+: { pod+: { securityContext+: { runAsUser: runAsUser } } } } },
          '#withSeLinuxChangePolicy':: d.fn(help="\"seLinuxChangePolicy defines how the container's SELinux label is applied to all volumes used by the Pod.\\nIt has no effect on nodes that do not support SELinux or to volumes does not support SELinux.\\nValid values are \\\"MountOption\\\" and \\\"Recursive\\\".\\n\\n\\\"Recursive\\\" means relabeling of all files on all Pod volumes by the container runtime.\\nThis may be slow for large volumes, but allows mixing privileged and unprivileged Pods sharing the same volume on the same node.\\n\\n\\\"MountOption\\\" mounts all eligible Pod volumes with `-o context` mount option.\\nThis requires all Pods that share the same volume to use the same SELinux label.\\nIt is not possible to share the same volume among privileged and unprivileged Pods.\\nEligible volumes are in-tree FibreChannel and iSCSI volumes, and all CSI volumes\\nwhose CSI driver announces SELinux support by setting spec.seLinuxMount: true in their\\nCSIDriver instance. Other volumes are always re-labelled recursively.\\n\\\"MountOption\\\" value is allowed only when SELinuxMount feature gate is enabled.\\n\\nIf not specified and SELinuxMount feature gate is enabled, \\\"MountOption\\\" is used.\\nIf not specified and SELinuxMount feature gate is disabled, \\\"MountOption\\\" is used for ReadWriteOncePod volumes\\nand \\\"Recursive\\\" for all other volumes.\\n\\nThis field affects only Pods that have SELinux label set, either in PodSecurityContext or in SecurityContext of all containers.\\n\\nAll Pods that use the same volume should use the same seLinuxChangePolicy, otherwise some pods can get stuck in ContainerCreating state.\\nNote that this field cannot be set when spec.os.name is windows.\"", args=[d.arg(name='seLinuxChangePolicy', type=d.T.string)]),
          withSeLinuxChangePolicy(seLinuxChangePolicy): { spec+: { statefulSet+: { pod+: { securityContext+: { seLinuxChangePolicy: seLinuxChangePolicy } } } } },
          '#withSupplementalGroups':: d.fn(help="\"A list of groups applied to the first process run in each container, in\\naddition to the container's primary GID and fsGroup (if specified).  If\\nthe SupplementalGroupsPolicy feature is enabled, the\\nsupplementalGroupsPolicy field determines whether these are in addition\\nto or instead of any group memberships defined in the container image.\\nIf unspecified, no additional groups are added, though group memberships\\ndefined in the container image may still be used, depending on the\\nsupplementalGroupsPolicy field.\\nNote that this field cannot be set when spec.os.name is windows.\"", args=[d.arg(name='supplementalGroups', type=d.T.array)]),
          withSupplementalGroups(supplementalGroups): { spec+: { statefulSet+: { pod+: { securityContext+: { supplementalGroups: if std.isArray(v=supplementalGroups) then supplementalGroups else [supplementalGroups] } } } } },
          '#withSupplementalGroupsMixin':: d.fn(help="\"A list of groups applied to the first process run in each container, in\\naddition to the container's primary GID and fsGroup (if specified).  If\\nthe SupplementalGroupsPolicy feature is enabled, the\\nsupplementalGroupsPolicy field determines whether these are in addition\\nto or instead of any group memberships defined in the container image.\\nIf unspecified, no additional groups are added, though group memberships\\ndefined in the container image may still be used, depending on the\\nsupplementalGroupsPolicy field.\\nNote that this field cannot be set when spec.os.name is windows.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='supplementalGroups', type=d.T.array)]),
          withSupplementalGroupsMixin(supplementalGroups): { spec+: { statefulSet+: { pod+: { securityContext+: { supplementalGroups+: if std.isArray(v=supplementalGroups) then supplementalGroups else [supplementalGroups] } } } } },
          '#withSupplementalGroupsPolicy':: d.fn(help='"Defines how supplemental groups of the first container processes are calculated.\\nValid values are \\"Merge\\" and \\"Strict\\". If not specified, \\"Merge\\" is used.\\n(Alpha) Using the field requires the SupplementalGroupsPolicy feature gate to be enabled\\nand the container runtime must implement support for this feature.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='supplementalGroupsPolicy', type=d.T.string)]),
          withSupplementalGroupsPolicy(supplementalGroupsPolicy): { spec+: { statefulSet+: { pod+: { securityContext+: { supplementalGroupsPolicy: supplementalGroupsPolicy } } } } },
          '#withSysctls':: d.fn(help='"Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported\\nsysctls (by the container runtime) might fail to launch.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='sysctls', type=d.T.array)]),
          withSysctls(sysctls): { spec+: { statefulSet+: { pod+: { securityContext+: { sysctls: if std.isArray(v=sysctls) then sysctls else [sysctls] } } } } },
          '#withSysctlsMixin':: d.fn(help='"Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported\\nsysctls (by the container runtime) might fail to launch.\\nNote that this field cannot be set when spec.os.name is windows."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='sysctls', type=d.T.array)]),
          withSysctlsMixin(sysctls): { spec+: { statefulSet+: { pod+: { securityContext+: { sysctls+: if std.isArray(v=sysctls) then sysctls else [sysctls] } } } } },
        },
        '#tailscaleContainer':: d.obj(help='"Configuration for the proxy container running tailscale."'),
        tailscaleContainer: {
          '#debug':: d.obj(help='"Configuration for enabling extra debug information in the container.\\nNot recommended for production use."'),
          debug: {
            '#withEnable':: d.fn(help="\"Enable tailscaled's HTTP pprof endpoints at \u003cpod-ip\u003e:9001/debug/pprof/\\nand internal debug metrics endpoint at \u003cpod-ip\u003e:9001/debug/metrics, where\\n9001 is a container port named \\\"debug\\\". The endpoints and their responses\\nmay change in backwards incompatible ways in the future, and should not\\nbe considered stable.\\n\\nIn 1.78.x and 1.80.x, this setting will default to the value of\\n.spec.metrics.enable, and requests to the \\\"metrics\\\" port matching the\\nmux pattern /debug/ will be forwarded to the \\\"debug\\\" port. In 1.82.x,\\nthis setting will default to false, and no requests will be proxied.\"", args=[d.arg(name='enable', type=d.T.boolean)]),
            withEnable(enable): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { debug+: { enable: enable } } } } } },
          },
          '#env':: d.obj(help='"List of environment variables to set in the container.\\nhttps://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#environment-variables\\nNote that environment variables provided here will take precedence\\nover Tailscale-specific environment variables set by the operator,\\nhowever running proxies with custom values for Tailscale environment\\nvariables (i.e TS_USERSPACE) is not recommended and might break in\\nthe future."'),
          env: {
            '#withName':: d.fn(help='"Name of the environment variable. Must be a C_IDENTIFIER."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withValue':: d.fn(help='"Variable references $(VAR_NAME) are expanded using the previously defined\\n environment variables in the container and any service environment\\nvariables. If a variable cannot be resolved, the reference in the input\\nstring will be unchanged. Double $$ are reduced to a single $, which\\nallows for escaping the $(VAR_NAME) syntax: i.e. \\"$$(VAR_NAME)\\" will\\nproduce the string literal \\"$(VAR_NAME)\\". Escaped references will never\\nbe expanded, regardless of whether the variable exists or not. Defaults\\nto \\"\\"."', args=[d.arg(name='value', type=d.T.string)]),
            withValue(value): { value: value },
          },
          '#resources':: d.obj(help='"Container resource requirements.\\nBy default Tailscale Kubernetes operator does not apply any resource\\nrequirements. The amount of resources required wil depend on the\\namount of resources the operator needs to parse, usage patterns and\\ncluster size.\\nhttps://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#resources"'),
          resources: {
            '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
            claims: {
              '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
              withRequest(request): { request: request },
            },
            '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
            withClaims(claims): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } } } } } },
            '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
            withClaimsMixin(claims): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } } } } } },
            '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
            withLimits(limits): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { resources+: { limits: limits } } } } } },
            '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
            withLimitsMixin(limits): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { resources+: { limits+: limits } } } } } },
            '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
            withRequests(requests): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { resources+: { requests: requests } } } } } },
            '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
            withRequestsMixin(requests): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { resources+: { requests+: requests } } } } } },
          },
          '#securityContext':: d.obj(help='"Container security context.\\nSecurity context specified here will override the security context set by the operator.\\nBy default the operator sets the Tailscale container and the Tailscale init container to privileged\\nfor proxies created for Tailscale ingress and egress Service, Connector and ProxyGroup.\\nYou can reduce the permissions of the Tailscale container to cap NET_ADMIN by\\ninstalling device plugin in your cluster and configuring the proxies tun device to be created\\nby the device plugin, see  https://github.com/tailscale/tailscale/issues/10814#issuecomment-2479977752\\nhttps://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#security-context"'),
          securityContext: {
            '#appArmorProfile':: d.obj(help="\"appArmorProfile is the AppArmor options to use by this container. If set, this profile\\noverrides the pod's appArmorProfile.\\nNote that this field cannot be set when spec.os.name is windows.\""),
            appArmorProfile: {
              '#withLocalhostProfile':: d.fn(help='"localhostProfile indicates a profile loaded on the node that should be used.\\nThe profile must be preconfigured on the node to work.\\nMust match the loaded name of the profile.\\nMust be set if and only if type is \\"Localhost\\"."', args=[d.arg(name='localhostProfile', type=d.T.string)]),
              withLocalhostProfile(localhostProfile): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { securityContext+: { appArmorProfile+: { localhostProfile: localhostProfile } } } } } } },
              '#withType':: d.fn(help="\"type indicates which kind of AppArmor profile will be applied.\\nValid options are:\\n  Localhost - a profile pre-loaded on the node.\\n  RuntimeDefault - the container runtime's default profile.\\n  Unconfined - no AppArmor enforcement.\"", args=[d.arg(name='type', type=d.T.string)]),
              withType(type): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { securityContext+: { appArmorProfile+: { type: type } } } } } } },
            },
            '#capabilities':: d.obj(help='"The capabilities to add/drop when running containers.\\nDefaults to the default set of capabilities granted by the container runtime.\\nNote that this field cannot be set when spec.os.name is windows."'),
            capabilities: {
              '#withAdd':: d.fn(help='"Added capabilities"', args=[d.arg(name='add', type=d.T.array)]),
              withAdd(add): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { securityContext+: { capabilities+: { add: if std.isArray(v=add) then add else [add] } } } } } } },
              '#withAddMixin':: d.fn(help='"Added capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='add', type=d.T.array)]),
              withAddMixin(add): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { securityContext+: { capabilities+: { add+: if std.isArray(v=add) then add else [add] } } } } } } },
              '#withDrop':: d.fn(help='"Removed capabilities"', args=[d.arg(name='drop', type=d.T.array)]),
              withDrop(drop): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { securityContext+: { capabilities+: { drop: if std.isArray(v=drop) then drop else [drop] } } } } } } },
              '#withDropMixin':: d.fn(help='"Removed capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='drop', type=d.T.array)]),
              withDropMixin(drop): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { securityContext+: { capabilities+: { drop+: if std.isArray(v=drop) then drop else [drop] } } } } } } },
            },
            '#seLinuxOptions':: d.obj(help='"The SELinux context to be applied to the container.\\nIf unspecified, the container runtime will allocate a random SELinux context for each\\ncontainer.  May also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."'),
            seLinuxOptions: {
              '#withLevel':: d.fn(help='"Level is SELinux level label that applies to the container."', args=[d.arg(name='level', type=d.T.string)]),
              withLevel(level): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { securityContext+: { seLinuxOptions+: { level: level } } } } } } },
              '#withRole':: d.fn(help='"Role is a SELinux role label that applies to the container."', args=[d.arg(name='role', type=d.T.string)]),
              withRole(role): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { securityContext+: { seLinuxOptions+: { role: role } } } } } } },
              '#withType':: d.fn(help='"Type is a SELinux type label that applies to the container."', args=[d.arg(name='type', type=d.T.string)]),
              withType(type): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { securityContext+: { seLinuxOptions+: { type: type } } } } } } },
              '#withUser':: d.fn(help='"User is a SELinux user label that applies to the container."', args=[d.arg(name='user', type=d.T.string)]),
              withUser(user): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { securityContext+: { seLinuxOptions+: { user: user } } } } } } },
            },
            '#seccompProfile':: d.obj(help='"The seccomp options to use by this container. If seccomp options are\\nprovided at both the pod & container level, the container options\\noverride the pod options.\\nNote that this field cannot be set when spec.os.name is windows."'),
            seccompProfile: {
              '#withLocalhostProfile':: d.fn(help="\"localhostProfile indicates a profile defined in a file on the node should be used.\\nThe profile must be preconfigured on the node to work.\\nMust be a descending path, relative to the kubelet's configured seccomp profile location.\\nMust be set if type is \\\"Localhost\\\". Must NOT be set for any other type.\"", args=[d.arg(name='localhostProfile', type=d.T.string)]),
              withLocalhostProfile(localhostProfile): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { securityContext+: { seccompProfile+: { localhostProfile: localhostProfile } } } } } } },
              '#withType':: d.fn(help='"type indicates which kind of seccomp profile will be applied.\\nValid options are:\\n\\nLocalhost - a profile defined in a file on the node should be used.\\nRuntimeDefault - the container runtime default profile should be used.\\nUnconfined - no profile should be applied."', args=[d.arg(name='type', type=d.T.string)]),
              withType(type): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { securityContext+: { seccompProfile+: { type: type } } } } } } },
            },
            '#windowsOptions':: d.obj(help='"The Windows specific settings applied to all containers.\\nIf unspecified, the options from the PodSecurityContext will be used.\\nIf set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is linux."'),
            windowsOptions: {
              '#withGmsaCredentialSpec':: d.fn(help='"GMSACredentialSpec is where the GMSA admission webhook\\n(https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the\\nGMSA credential spec named by the GMSACredentialSpecName field."', args=[d.arg(name='gmsaCredentialSpec', type=d.T.string)]),
              withGmsaCredentialSpec(gmsaCredentialSpec): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { securityContext+: { windowsOptions+: { gmsaCredentialSpec: gmsaCredentialSpec } } } } } } },
              '#withGmsaCredentialSpecName':: d.fn(help='"GMSACredentialSpecName is the name of the GMSA credential spec to use."', args=[d.arg(name='gmsaCredentialSpecName', type=d.T.string)]),
              withGmsaCredentialSpecName(gmsaCredentialSpecName): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { securityContext+: { windowsOptions+: { gmsaCredentialSpecName: gmsaCredentialSpecName } } } } } } },
              '#withHostProcess':: d.fn(help="\"HostProcess determines if a container should be run as a 'Host Process' container.\\nAll of a Pod's containers must have the same effective HostProcess value\\n(it is not allowed to have a mix of HostProcess containers and non-HostProcess containers).\\nIn addition, if HostProcess is true then HostNetwork must also be set to true.\"", args=[d.arg(name='hostProcess', type=d.T.boolean)]),
              withHostProcess(hostProcess): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { securityContext+: { windowsOptions+: { hostProcess: hostProcess } } } } } } },
              '#withRunAsUserName':: d.fn(help='"The UserName in Windows to run the entrypoint of the container process.\\nDefaults to the user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext. If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsUserName', type=d.T.string)]),
              withRunAsUserName(runAsUserName): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { securityContext+: { windowsOptions+: { runAsUserName: runAsUserName } } } } } } },
            },
            '#withAllowPrivilegeEscalation':: d.fn(help='"AllowPrivilegeEscalation controls whether a process can gain more\\nprivileges than its parent process. This bool directly controls if\\nthe no_new_privs flag will be set on the container process.\\nAllowPrivilegeEscalation is true always when the container is:\\n1) run as Privileged\\n2) has CAP_SYS_ADMIN\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='allowPrivilegeEscalation', type=d.T.boolean)]),
            withAllowPrivilegeEscalation(allowPrivilegeEscalation): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { securityContext+: { allowPrivilegeEscalation: allowPrivilegeEscalation } } } } } },
            '#withPrivileged':: d.fn(help='"Run container in privileged mode.\\nProcesses in privileged containers are essentially equivalent to root on the host.\\nDefaults to false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='privileged', type=d.T.boolean)]),
            withPrivileged(privileged): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { securityContext+: { privileged: privileged } } } } } },
            '#withProcMount':: d.fn(help='"procMount denotes the type of proc mount to use for the containers.\\nThe default value is Default which uses the container runtime defaults for\\nreadonly paths and masked paths.\\nThis requires the ProcMountType feature flag to be enabled.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='procMount', type=d.T.string)]),
            withProcMount(procMount): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { securityContext+: { procMount: procMount } } } } } },
            '#withReadOnlyRootFilesystem':: d.fn(help='"Whether this container has a read-only root filesystem.\\nDefault is false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='readOnlyRootFilesystem', type=d.T.boolean)]),
            withReadOnlyRootFilesystem(readOnlyRootFilesystem): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { securityContext+: { readOnlyRootFilesystem: readOnlyRootFilesystem } } } } } },
            '#withRunAsGroup':: d.fn(help='"The GID to run the entrypoint of the container process.\\nUses runtime default if unset.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsGroup', type=d.T.integer)]),
            withRunAsGroup(runAsGroup): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { securityContext+: { runAsGroup: runAsGroup } } } } } },
            '#withRunAsNonRoot':: d.fn(help='"Indicates that the container must run as a non-root user.\\nIf true, the Kubelet will validate the image at runtime to ensure that it\\ndoes not run as UID 0 (root) and fail to start the container if it does.\\nIf unset or false, no such validation will be performed.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsNonRoot', type=d.T.boolean)]),
            withRunAsNonRoot(runAsNonRoot): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { securityContext+: { runAsNonRoot: runAsNonRoot } } } } } },
            '#withRunAsUser':: d.fn(help='"The UID to run the entrypoint of the container process.\\nDefaults to user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsUser', type=d.T.integer)]),
            withRunAsUser(runAsUser): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { securityContext+: { runAsUser: runAsUser } } } } } },
          },
          '#withEnv':: d.fn(help='"List of environment variables to set in the container.\\nhttps://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#environment-variables\\nNote that environment variables provided here will take precedence\\nover Tailscale-specific environment variables set by the operator,\\nhowever running proxies with custom values for Tailscale environment\\nvariables (i.e TS_USERSPACE) is not recommended and might break in\\nthe future."', args=[d.arg(name='env', type=d.T.array)]),
          withEnv(env): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { env: if std.isArray(v=env) then env else [env] } } } } },
          '#withEnvMixin':: d.fn(help='"List of environment variables to set in the container.\\nhttps://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#environment-variables\\nNote that environment variables provided here will take precedence\\nover Tailscale-specific environment variables set by the operator,\\nhowever running proxies with custom values for Tailscale environment\\nvariables (i.e TS_USERSPACE) is not recommended and might break in\\nthe future."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='env', type=d.T.array)]),
          withEnvMixin(env): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { env+: if std.isArray(v=env) then env else [env] } } } } },
          '#withImage':: d.fn(help="\"Container image name. By default images are pulled from docker.io/tailscale,\\nbut the official images are also available at ghcr.io/tailscale.\\n\\nFor all uses except on ProxyGroups of type \\\"kube-apiserver\\\", this image must\\nbe either tailscale/tailscale, or an equivalent mirror of that image.\\nTo apply to ProxyGroups of type \\\"kube-apiserver\\\", this image must be\\ntailscale/k8s-proxy or a mirror of that image.\\n\\nFor \\\"tailscale/tailscale\\\"-based proxies, specifying image name here will\\noverride any proxy image values specified via the Kubernetes operator's\\nHelm chart values or PROXY_IMAGE env var in the operator Deployment.\\nFor \\\"tailscale/k8s-proxy\\\"-based proxies, there is currently no way to\\nconfigure your own default, and this field is the only way to use a\\ncustom image.\\n\\nhttps://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#image\"", args=[d.arg(name='image', type=d.T.string)]),
          withImage(image): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { image: image } } } } },
          '#withImagePullPolicy':: d.fn(help='"Image pull policy. One of Always, Never, IfNotPresent. Defaults to Always.\\nhttps://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#image"', args=[d.arg(name='imagePullPolicy', type=d.T.string)]),
          withImagePullPolicy(imagePullPolicy): { spec+: { statefulSet+: { pod+: { tailscaleContainer+: { imagePullPolicy: imagePullPolicy } } } } },
        },
        '#tailscaleInitContainer':: d.obj(help='"Configuration for the proxy init container that enables forwarding.\\nNot valid to apply to ProxyGroups of type \\"kube-apiserver\\"."'),
        tailscaleInitContainer: {
          '#debug':: d.obj(help='"Configuration for enabling extra debug information in the container.\\nNot recommended for production use."'),
          debug: {
            '#withEnable':: d.fn(help="\"Enable tailscaled's HTTP pprof endpoints at \u003cpod-ip\u003e:9001/debug/pprof/\\nand internal debug metrics endpoint at \u003cpod-ip\u003e:9001/debug/metrics, where\\n9001 is a container port named \\\"debug\\\". The endpoints and their responses\\nmay change in backwards incompatible ways in the future, and should not\\nbe considered stable.\\n\\nIn 1.78.x and 1.80.x, this setting will default to the value of\\n.spec.metrics.enable, and requests to the \\\"metrics\\\" port matching the\\nmux pattern /debug/ will be forwarded to the \\\"debug\\\" port. In 1.82.x,\\nthis setting will default to false, and no requests will be proxied.\"", args=[d.arg(name='enable', type=d.T.boolean)]),
            withEnable(enable): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { debug+: { enable: enable } } } } } },
          },
          '#env':: d.obj(help='"List of environment variables to set in the container.\\nhttps://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#environment-variables\\nNote that environment variables provided here will take precedence\\nover Tailscale-specific environment variables set by the operator,\\nhowever running proxies with custom values for Tailscale environment\\nvariables (i.e TS_USERSPACE) is not recommended and might break in\\nthe future."'),
          env: {
            '#withName':: d.fn(help='"Name of the environment variable. Must be a C_IDENTIFIER."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withValue':: d.fn(help='"Variable references $(VAR_NAME) are expanded using the previously defined\\n environment variables in the container and any service environment\\nvariables. If a variable cannot be resolved, the reference in the input\\nstring will be unchanged. Double $$ are reduced to a single $, which\\nallows for escaping the $(VAR_NAME) syntax: i.e. \\"$$(VAR_NAME)\\" will\\nproduce the string literal \\"$(VAR_NAME)\\". Escaped references will never\\nbe expanded, regardless of whether the variable exists or not. Defaults\\nto \\"\\"."', args=[d.arg(name='value', type=d.T.string)]),
            withValue(value): { value: value },
          },
          '#resources':: d.obj(help='"Container resource requirements.\\nBy default Tailscale Kubernetes operator does not apply any resource\\nrequirements. The amount of resources required wil depend on the\\namount of resources the operator needs to parse, usage patterns and\\ncluster size.\\nhttps://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#resources"'),
          resources: {
            '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
            claims: {
              '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
              withRequest(request): { request: request },
            },
            '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
            withClaims(claims): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } } } } } },
            '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
            withClaimsMixin(claims): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } } } } } },
            '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
            withLimits(limits): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { resources+: { limits: limits } } } } } },
            '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
            withLimitsMixin(limits): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { resources+: { limits+: limits } } } } } },
            '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
            withRequests(requests): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { resources+: { requests: requests } } } } } },
            '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
            withRequestsMixin(requests): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { resources+: { requests+: requests } } } } } },
          },
          '#securityContext':: d.obj(help='"Container security context.\\nSecurity context specified here will override the security context set by the operator.\\nBy default the operator sets the Tailscale container and the Tailscale init container to privileged\\nfor proxies created for Tailscale ingress and egress Service, Connector and ProxyGroup.\\nYou can reduce the permissions of the Tailscale container to cap NET_ADMIN by\\ninstalling device plugin in your cluster and configuring the proxies tun device to be created\\nby the device plugin, see  https://github.com/tailscale/tailscale/issues/10814#issuecomment-2479977752\\nhttps://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#security-context"'),
          securityContext: {
            '#appArmorProfile':: d.obj(help="\"appArmorProfile is the AppArmor options to use by this container. If set, this profile\\noverrides the pod's appArmorProfile.\\nNote that this field cannot be set when spec.os.name is windows.\""),
            appArmorProfile: {
              '#withLocalhostProfile':: d.fn(help='"localhostProfile indicates a profile loaded on the node that should be used.\\nThe profile must be preconfigured on the node to work.\\nMust match the loaded name of the profile.\\nMust be set if and only if type is \\"Localhost\\"."', args=[d.arg(name='localhostProfile', type=d.T.string)]),
              withLocalhostProfile(localhostProfile): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { securityContext+: { appArmorProfile+: { localhostProfile: localhostProfile } } } } } } },
              '#withType':: d.fn(help="\"type indicates which kind of AppArmor profile will be applied.\\nValid options are:\\n  Localhost - a profile pre-loaded on the node.\\n  RuntimeDefault - the container runtime's default profile.\\n  Unconfined - no AppArmor enforcement.\"", args=[d.arg(name='type', type=d.T.string)]),
              withType(type): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { securityContext+: { appArmorProfile+: { type: type } } } } } } },
            },
            '#capabilities':: d.obj(help='"The capabilities to add/drop when running containers.\\nDefaults to the default set of capabilities granted by the container runtime.\\nNote that this field cannot be set when spec.os.name is windows."'),
            capabilities: {
              '#withAdd':: d.fn(help='"Added capabilities"', args=[d.arg(name='add', type=d.T.array)]),
              withAdd(add): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { securityContext+: { capabilities+: { add: if std.isArray(v=add) then add else [add] } } } } } } },
              '#withAddMixin':: d.fn(help='"Added capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='add', type=d.T.array)]),
              withAddMixin(add): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { securityContext+: { capabilities+: { add+: if std.isArray(v=add) then add else [add] } } } } } } },
              '#withDrop':: d.fn(help='"Removed capabilities"', args=[d.arg(name='drop', type=d.T.array)]),
              withDrop(drop): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { securityContext+: { capabilities+: { drop: if std.isArray(v=drop) then drop else [drop] } } } } } } },
              '#withDropMixin':: d.fn(help='"Removed capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='drop', type=d.T.array)]),
              withDropMixin(drop): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { securityContext+: { capabilities+: { drop+: if std.isArray(v=drop) then drop else [drop] } } } } } } },
            },
            '#seLinuxOptions':: d.obj(help='"The SELinux context to be applied to the container.\\nIf unspecified, the container runtime will allocate a random SELinux context for each\\ncontainer.  May also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."'),
            seLinuxOptions: {
              '#withLevel':: d.fn(help='"Level is SELinux level label that applies to the container."', args=[d.arg(name='level', type=d.T.string)]),
              withLevel(level): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { securityContext+: { seLinuxOptions+: { level: level } } } } } } },
              '#withRole':: d.fn(help='"Role is a SELinux role label that applies to the container."', args=[d.arg(name='role', type=d.T.string)]),
              withRole(role): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { securityContext+: { seLinuxOptions+: { role: role } } } } } } },
              '#withType':: d.fn(help='"Type is a SELinux type label that applies to the container."', args=[d.arg(name='type', type=d.T.string)]),
              withType(type): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { securityContext+: { seLinuxOptions+: { type: type } } } } } } },
              '#withUser':: d.fn(help='"User is a SELinux user label that applies to the container."', args=[d.arg(name='user', type=d.T.string)]),
              withUser(user): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { securityContext+: { seLinuxOptions+: { user: user } } } } } } },
            },
            '#seccompProfile':: d.obj(help='"The seccomp options to use by this container. If seccomp options are\\nprovided at both the pod & container level, the container options\\noverride the pod options.\\nNote that this field cannot be set when spec.os.name is windows."'),
            seccompProfile: {
              '#withLocalhostProfile':: d.fn(help="\"localhostProfile indicates a profile defined in a file on the node should be used.\\nThe profile must be preconfigured on the node to work.\\nMust be a descending path, relative to the kubelet's configured seccomp profile location.\\nMust be set if type is \\\"Localhost\\\". Must NOT be set for any other type.\"", args=[d.arg(name='localhostProfile', type=d.T.string)]),
              withLocalhostProfile(localhostProfile): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { securityContext+: { seccompProfile+: { localhostProfile: localhostProfile } } } } } } },
              '#withType':: d.fn(help='"type indicates which kind of seccomp profile will be applied.\\nValid options are:\\n\\nLocalhost - a profile defined in a file on the node should be used.\\nRuntimeDefault - the container runtime default profile should be used.\\nUnconfined - no profile should be applied."', args=[d.arg(name='type', type=d.T.string)]),
              withType(type): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { securityContext+: { seccompProfile+: { type: type } } } } } } },
            },
            '#windowsOptions':: d.obj(help='"The Windows specific settings applied to all containers.\\nIf unspecified, the options from the PodSecurityContext will be used.\\nIf set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is linux."'),
            windowsOptions: {
              '#withGmsaCredentialSpec':: d.fn(help='"GMSACredentialSpec is where the GMSA admission webhook\\n(https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the\\nGMSA credential spec named by the GMSACredentialSpecName field."', args=[d.arg(name='gmsaCredentialSpec', type=d.T.string)]),
              withGmsaCredentialSpec(gmsaCredentialSpec): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { securityContext+: { windowsOptions+: { gmsaCredentialSpec: gmsaCredentialSpec } } } } } } },
              '#withGmsaCredentialSpecName':: d.fn(help='"GMSACredentialSpecName is the name of the GMSA credential spec to use."', args=[d.arg(name='gmsaCredentialSpecName', type=d.T.string)]),
              withGmsaCredentialSpecName(gmsaCredentialSpecName): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { securityContext+: { windowsOptions+: { gmsaCredentialSpecName: gmsaCredentialSpecName } } } } } } },
              '#withHostProcess':: d.fn(help="\"HostProcess determines if a container should be run as a 'Host Process' container.\\nAll of a Pod's containers must have the same effective HostProcess value\\n(it is not allowed to have a mix of HostProcess containers and non-HostProcess containers).\\nIn addition, if HostProcess is true then HostNetwork must also be set to true.\"", args=[d.arg(name='hostProcess', type=d.T.boolean)]),
              withHostProcess(hostProcess): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { securityContext+: { windowsOptions+: { hostProcess: hostProcess } } } } } } },
              '#withRunAsUserName':: d.fn(help='"The UserName in Windows to run the entrypoint of the container process.\\nDefaults to the user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext. If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsUserName', type=d.T.string)]),
              withRunAsUserName(runAsUserName): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { securityContext+: { windowsOptions+: { runAsUserName: runAsUserName } } } } } } },
            },
            '#withAllowPrivilegeEscalation':: d.fn(help='"AllowPrivilegeEscalation controls whether a process can gain more\\nprivileges than its parent process. This bool directly controls if\\nthe no_new_privs flag will be set on the container process.\\nAllowPrivilegeEscalation is true always when the container is:\\n1) run as Privileged\\n2) has CAP_SYS_ADMIN\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='allowPrivilegeEscalation', type=d.T.boolean)]),
            withAllowPrivilegeEscalation(allowPrivilegeEscalation): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { securityContext+: { allowPrivilegeEscalation: allowPrivilegeEscalation } } } } } },
            '#withPrivileged':: d.fn(help='"Run container in privileged mode.\\nProcesses in privileged containers are essentially equivalent to root on the host.\\nDefaults to false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='privileged', type=d.T.boolean)]),
            withPrivileged(privileged): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { securityContext+: { privileged: privileged } } } } } },
            '#withProcMount':: d.fn(help='"procMount denotes the type of proc mount to use for the containers.\\nThe default value is Default which uses the container runtime defaults for\\nreadonly paths and masked paths.\\nThis requires the ProcMountType feature flag to be enabled.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='procMount', type=d.T.string)]),
            withProcMount(procMount): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { securityContext+: { procMount: procMount } } } } } },
            '#withReadOnlyRootFilesystem':: d.fn(help='"Whether this container has a read-only root filesystem.\\nDefault is false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='readOnlyRootFilesystem', type=d.T.boolean)]),
            withReadOnlyRootFilesystem(readOnlyRootFilesystem): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { securityContext+: { readOnlyRootFilesystem: readOnlyRootFilesystem } } } } } },
            '#withRunAsGroup':: d.fn(help='"The GID to run the entrypoint of the container process.\\nUses runtime default if unset.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsGroup', type=d.T.integer)]),
            withRunAsGroup(runAsGroup): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { securityContext+: { runAsGroup: runAsGroup } } } } } },
            '#withRunAsNonRoot':: d.fn(help='"Indicates that the container must run as a non-root user.\\nIf true, the Kubelet will validate the image at runtime to ensure that it\\ndoes not run as UID 0 (root) and fail to start the container if it does.\\nIf unset or false, no such validation will be performed.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsNonRoot', type=d.T.boolean)]),
            withRunAsNonRoot(runAsNonRoot): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { securityContext+: { runAsNonRoot: runAsNonRoot } } } } } },
            '#withRunAsUser':: d.fn(help='"The UID to run the entrypoint of the container process.\\nDefaults to user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsUser', type=d.T.integer)]),
            withRunAsUser(runAsUser): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { securityContext+: { runAsUser: runAsUser } } } } } },
          },
          '#withEnv':: d.fn(help='"List of environment variables to set in the container.\\nhttps://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#environment-variables\\nNote that environment variables provided here will take precedence\\nover Tailscale-specific environment variables set by the operator,\\nhowever running proxies with custom values for Tailscale environment\\nvariables (i.e TS_USERSPACE) is not recommended and might break in\\nthe future."', args=[d.arg(name='env', type=d.T.array)]),
          withEnv(env): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { env: if std.isArray(v=env) then env else [env] } } } } },
          '#withEnvMixin':: d.fn(help='"List of environment variables to set in the container.\\nhttps://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#environment-variables\\nNote that environment variables provided here will take precedence\\nover Tailscale-specific environment variables set by the operator,\\nhowever running proxies with custom values for Tailscale environment\\nvariables (i.e TS_USERSPACE) is not recommended and might break in\\nthe future."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='env', type=d.T.array)]),
          withEnvMixin(env): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { env+: if std.isArray(v=env) then env else [env] } } } } },
          '#withImage':: d.fn(help="\"Container image name. By default images are pulled from docker.io/tailscale,\\nbut the official images are also available at ghcr.io/tailscale.\\n\\nFor all uses except on ProxyGroups of type \\\"kube-apiserver\\\", this image must\\nbe either tailscale/tailscale, or an equivalent mirror of that image.\\nTo apply to ProxyGroups of type \\\"kube-apiserver\\\", this image must be\\ntailscale/k8s-proxy or a mirror of that image.\\n\\nFor \\\"tailscale/tailscale\\\"-based proxies, specifying image name here will\\noverride any proxy image values specified via the Kubernetes operator's\\nHelm chart values or PROXY_IMAGE env var in the operator Deployment.\\nFor \\\"tailscale/k8s-proxy\\\"-based proxies, there is currently no way to\\nconfigure your own default, and this field is the only way to use a\\ncustom image.\\n\\nhttps://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#image\"", args=[d.arg(name='image', type=d.T.string)]),
          withImage(image): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { image: image } } } } },
          '#withImagePullPolicy':: d.fn(help='"Image pull policy. One of Always, Never, IfNotPresent. Defaults to Always.\\nhttps://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#image"', args=[d.arg(name='imagePullPolicy', type=d.T.string)]),
          withImagePullPolicy(imagePullPolicy): { spec+: { statefulSet+: { pod+: { tailscaleInitContainer+: { imagePullPolicy: imagePullPolicy } } } } },
        },
        '#tolerations':: d.obj(help="\"Proxy Pod's tolerations.\\nBy default Tailscale Kubernetes operator does not apply any\\ntolerations.\\nhttps://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling\""),
        tolerations: {
          '#withEffect':: d.fn(help='"Effect indicates the taint effect to match. Empty means match all taint effects.\\nWhen specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute."', args=[d.arg(name='effect', type=d.T.string)]),
          withEffect(effect): { effect: effect },
          '#withKey':: d.fn(help='"Key is the taint key that the toleration applies to. Empty means match all taint keys.\\nIf the key is empty, operator must be Exists; this combination means to match all values and all keys."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { key: key },
          '#withOperator':: d.fn(help="\"Operator represents a key's relationship to the value.\\nValid operators are Exists and Equal. Defaults to Equal.\\nExists is equivalent to wildcard for value, so that a pod can\\ntolerate all taints of a particular category.\"", args=[d.arg(name='operator', type=d.T.string)]),
          withOperator(operator): { operator: operator },
          '#withTolerationSeconds':: d.fn(help='"TolerationSeconds represents the period of time the toleration (which must be\\nof effect NoExecute, otherwise this field is ignored) tolerates the taint. By default,\\nit is not set, which means tolerate the taint forever (do not evict). Zero and\\nnegative values will be treated as 0 (evict immediately) by the system."', args=[d.arg(name='tolerationSeconds', type=d.T.integer)]),
          withTolerationSeconds(tolerationSeconds): { tolerationSeconds: tolerationSeconds },
          '#withValue':: d.fn(help='"Value is the taint value the toleration matches to.\\nIf the operator is Exists, the value should be empty, otherwise just a regular string."', args=[d.arg(name='value', type=d.T.string)]),
          withValue(value): { value: value },
        },
        '#topologySpreadConstraints':: d.obj(help="\"Proxy Pod's topology spread constraints.\\nBy default Tailscale Kubernetes operator does not apply any topology spread constraints.\\nhttps://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/\""),
        topologySpreadConstraints: {
          '#labelSelector':: d.obj(help='"LabelSelector is used to find matching pods.\\nPods that match this label selector are counted to determine the number of pods\\nin their corresponding topology domain."'),
          labelSelector: {
            '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
            matchExpressions: {
              '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { key: key },
              '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
              withOperator(operator): { operator: operator },
              '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
              withValues(values): { values: if std.isArray(v=values) then values else [values] },
              '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
              withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
            },
            '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
            withMatchExpressions(matchExpressions): { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
            '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
            withMatchExpressionsMixin(matchExpressions): { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
            '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
            withMatchLabels(matchLabels): { labelSelector+: { matchLabels: matchLabels } },
            '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
            withMatchLabelsMixin(matchLabels): { labelSelector+: { matchLabels+: matchLabels } },
          },
          '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select the pods over which\\nspreading will be calculated. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are ANDed with labelSelector\\nto select the group of existing pods over which spreading will be calculated\\nfor the incoming pod. The same key is forbidden to exist in both MatchLabelKeys and LabelSelector.\\nMatchLabelKeys cannot be set when LabelSelector isn't set.\\nKeys that don't exist in the incoming pod labels will\\nbe ignored. A null or empty list means only match against labelSelector.\\n\\nThis is a beta field and requires the MatchLabelKeysInPodTopologySpread feature gate to be enabled (enabled by default).\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
          withMatchLabelKeys(matchLabelKeys): { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
          '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select the pods over which\\nspreading will be calculated. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are ANDed with labelSelector\\nto select the group of existing pods over which spreading will be calculated\\nfor the incoming pod. The same key is forbidden to exist in both MatchLabelKeys and LabelSelector.\\nMatchLabelKeys cannot be set when LabelSelector isn't set.\\nKeys that don't exist in the incoming pod labels will\\nbe ignored. A null or empty list means only match against labelSelector.\\n\\nThis is a beta field and requires the MatchLabelKeysInPodTopologySpread feature gate to be enabled (enabled by default).\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
          withMatchLabelKeysMixin(matchLabelKeys): { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
          '#withMaxSkew':: d.fn(help="\"MaxSkew describes the degree to which pods may be unevenly distributed.\\nWhen `whenUnsatisfiable=DoNotSchedule`, it is the maximum permitted difference\\nbetween the number of matching pods in the target topology and the global minimum.\\nThe global minimum is the minimum number of matching pods in an eligible domain\\nor zero if the number of eligible domains is less than MinDomains.\\nFor example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same\\nlabelSelector spread as 2/2/1:\\nIn this case, the global minimum is 1.\\n| zone1 | zone2 | zone3 |\\n|  P P  |  P P  |   P   |\\n- if MaxSkew is 1, incoming pod can only be scheduled to zone3 to become 2/2/2;\\nscheduling it onto zone1(zone2) would make the ActualSkew(3-1) on zone1(zone2)\\nviolate MaxSkew(1).\\n- if MaxSkew is 2, incoming pod can be scheduled onto any zone.\\nWhen `whenUnsatisfiable=ScheduleAnyway`, it is used to give higher precedence\\nto topologies that satisfy it.\\nIt's a required field. Default value is 1 and 0 is not allowed.\"", args=[d.arg(name='maxSkew', type=d.T.integer)]),
          withMaxSkew(maxSkew): { maxSkew: maxSkew },
          '#withMinDomains':: d.fn(help="\"MinDomains indicates a minimum number of eligible domains.\\nWhen the number of eligible domains with matching topology keys is less than minDomains,\\nPod Topology Spread treats \\\"global minimum\\\" as 0, and then the calculation of Skew is performed.\\nAnd when the number of eligible domains with matching topology keys equals or greater than minDomains,\\nthis value has no effect on scheduling.\\nAs a result, when the number of eligible domains is less than minDomains,\\nscheduler won't schedule more than maxSkew Pods to those domains.\\nIf value is nil, the constraint behaves as if MinDomains is equal to 1.\\nValid values are integers greater than 0.\\nWhen value is not nil, WhenUnsatisfiable must be DoNotSchedule.\\n\\nFor example, in a 3-zone cluster, MaxSkew is set to 2, MinDomains is set to 5 and pods with the same\\nlabelSelector spread as 2/2/2:\\n| zone1 | zone2 | zone3 |\\n|  P P  |  P P  |  P P  |\\nThe number of domains is less than 5(MinDomains), so \\\"global minimum\\\" is treated as 0.\\nIn this situation, new pod with the same labelSelector cannot be scheduled,\\nbecause computed skew will be 3(3 - 0) if new Pod is scheduled to any of the three zones,\\nit will violate MaxSkew.\"", args=[d.arg(name='minDomains', type=d.T.integer)]),
          withMinDomains(minDomains): { minDomains: minDomains },
          '#withNodeAffinityPolicy':: d.fn(help="\"NodeAffinityPolicy indicates how we will treat Pod's nodeAffinity/nodeSelector\\nwhen calculating pod topology spread skew. Options are:\\n- Honor: only nodes matching nodeAffinity/nodeSelector are included in the calculations.\\n- Ignore: nodeAffinity/nodeSelector are ignored. All nodes are included in the calculations.\\n\\nIf this value is nil, the behavior is equivalent to the Honor policy.\"", args=[d.arg(name='nodeAffinityPolicy', type=d.T.string)]),
          withNodeAffinityPolicy(nodeAffinityPolicy): { nodeAffinityPolicy: nodeAffinityPolicy },
          '#withNodeTaintsPolicy':: d.fn(help='"NodeTaintsPolicy indicates how we will treat node taints when calculating\\npod topology spread skew. Options are:\\n- Honor: nodes without taints, along with tainted nodes for which the incoming pod\\nhas a toleration, are included.\\n- Ignore: node taints are ignored. All nodes are included.\\n\\nIf this value is nil, the behavior is equivalent to the Ignore policy."', args=[d.arg(name='nodeTaintsPolicy', type=d.T.string)]),
          withNodeTaintsPolicy(nodeTaintsPolicy): { nodeTaintsPolicy: nodeTaintsPolicy },
          '#withTopologyKey':: d.fn(help="\"TopologyKey is the key of node labels. Nodes that have a label with this key\\nand identical values are considered to be in the same topology.\\nWe consider each \u003ckey, value\u003e as a \\\"bucket\\\", and try to put balanced number\\nof pods into each bucket.\\nWe define a domain as a particular instance of a topology.\\nAlso, we define an eligible domain as a domain whose nodes meet the requirements of\\nnodeAffinityPolicy and nodeTaintsPolicy.\\ne.g. If TopologyKey is \\\"kubernetes.io/hostname\\\", each Node is a domain of that topology.\\nAnd, if TopologyKey is \\\"topology.kubernetes.io/zone\\\", each zone is a domain of that topology.\\nIt's a required field.\"", args=[d.arg(name='topologyKey', type=d.T.string)]),
          withTopologyKey(topologyKey): { topologyKey: topologyKey },
          '#withWhenUnsatisfiable':: d.fn(help="\"WhenUnsatisfiable indicates how to deal with a pod if it doesn't satisfy\\nthe spread constraint.\\n- DoNotSchedule (default) tells the scheduler not to schedule it.\\n- ScheduleAnyway tells the scheduler to schedule the pod in any location,\\n  but giving higher precedence to topologies that would help reduce the\\n  skew.\\nA constraint is considered \\\"Unsatisfiable\\\" for an incoming pod\\nif and only if every possible node assignment for that pod would violate\\n\\\"MaxSkew\\\" on some topology.\\nFor example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same\\nlabelSelector spread as 3/1/1:\\n| zone1 | zone2 | zone3 |\\n| P P P |   P   |   P   |\\nIf WhenUnsatisfiable is set to DoNotSchedule, incoming pod can only be scheduled\\nto zone2(zone3) to become 3/2/1(3/1/2) as ActualSkew(2-1) on zone2(zone3) satisfies\\nMaxSkew(1). In other words, the cluster can still be imbalanced, but scheduler\\nwon't make it *more* imbalanced.\\nIt's a required field.\"", args=[d.arg(name='whenUnsatisfiable', type=d.T.string)]),
          withWhenUnsatisfiable(whenUnsatisfiable): { whenUnsatisfiable: whenUnsatisfiable },
        },
        '#withAnnotations':: d.fn(help='"Annotations that will be added to the proxy Pod.\\nAny annotations specified here will be merged with the default\\nannotations applied to the Pod by the Tailscale Kubernetes operator.\\nAnnotations must be valid Kubernetes annotations.\\nhttps://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/#syntax-and-character-set"', args=[d.arg(name='annotations', type=d.T.object)]),
        withAnnotations(annotations): { spec+: { statefulSet+: { pod+: { annotations: annotations } } } },
        '#withAnnotationsMixin':: d.fn(help='"Annotations that will be added to the proxy Pod.\\nAny annotations specified here will be merged with the default\\nannotations applied to the Pod by the Tailscale Kubernetes operator.\\nAnnotations must be valid Kubernetes annotations.\\nhttps://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/#syntax-and-character-set"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
        withAnnotationsMixin(annotations): { spec+: { statefulSet+: { pod+: { annotations+: annotations } } } },
        '#withDnsPolicy':: d.fn(help='"DNSPolicy defines how DNS will be configured for the proxy Pod.\\nBy default the Tailscale Kubernetes Operator does not set a DNS policy (uses cluster default).\\nhttps://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-s-dns-policy"', args=[d.arg(name='dnsPolicy', type=d.T.string)]),
        withDnsPolicy(dnsPolicy): { spec+: { statefulSet+: { pod+: { dnsPolicy: dnsPolicy } } } },
        '#withImagePullSecrets':: d.fn(help="\"Proxy Pod's image pull Secrets.\\nhttps://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#PodSpec\"", args=[d.arg(name='imagePullSecrets', type=d.T.array)]),
        withImagePullSecrets(imagePullSecrets): { spec+: { statefulSet+: { pod+: { imagePullSecrets: if std.isArray(v=imagePullSecrets) then imagePullSecrets else [imagePullSecrets] } } } },
        '#withImagePullSecretsMixin':: d.fn(help="\"Proxy Pod's image pull Secrets.\\nhttps://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#PodSpec\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='imagePullSecrets', type=d.T.array)]),
        withImagePullSecretsMixin(imagePullSecrets): { spec+: { statefulSet+: { pod+: { imagePullSecrets+: if std.isArray(v=imagePullSecrets) then imagePullSecrets else [imagePullSecrets] } } } },
        '#withLabels':: d.fn(help='"Labels that will be added to the proxy Pod.\\nAny labels specified here will be merged with the default labels\\napplied to the Pod by the Tailscale Kubernetes operator.\\nLabel keys and values must be valid Kubernetes label keys and values.\\nhttps://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#syntax-and-character-set"', args=[d.arg(name='labels', type=d.T.object)]),
        withLabels(labels): { spec+: { statefulSet+: { pod+: { labels: labels } } } },
        '#withLabelsMixin':: d.fn(help='"Labels that will be added to the proxy Pod.\\nAny labels specified here will be merged with the default labels\\napplied to the Pod by the Tailscale Kubernetes operator.\\nLabel keys and values must be valid Kubernetes label keys and values.\\nhttps://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#syntax-and-character-set"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
        withLabelsMixin(labels): { spec+: { statefulSet+: { pod+: { labels+: labels } } } },
        '#withNodeName':: d.fn(help="\"Proxy Pod's node name.\\nhttps://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling\"", args=[d.arg(name='nodeName', type=d.T.string)]),
        withNodeName(nodeName): { spec+: { statefulSet+: { pod+: { nodeName: nodeName } } } },
        '#withNodeSelector':: d.fn(help="\"Proxy Pod's node selector.\\nBy default Tailscale Kubernetes operator does not apply any node\\nselector.\\nhttps://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling\"", args=[d.arg(name='nodeSelector', type=d.T.object)]),
        withNodeSelector(nodeSelector): { spec+: { statefulSet+: { pod+: { nodeSelector: nodeSelector } } } },
        '#withNodeSelectorMixin':: d.fn(help="\"Proxy Pod's node selector.\\nBy default Tailscale Kubernetes operator does not apply any node\\nselector.\\nhttps://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='nodeSelector', type=d.T.object)]),
        withNodeSelectorMixin(nodeSelector): { spec+: { statefulSet+: { pod+: { nodeSelector+: nodeSelector } } } },
        '#withPriorityClassName':: d.fn(help='"PriorityClassName for the proxy Pod.\\nBy default Tailscale Kubernetes operator does not apply any priority class.\\nhttps://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling"', args=[d.arg(name='priorityClassName', type=d.T.string)]),
        withPriorityClassName(priorityClassName): { spec+: { statefulSet+: { pod+: { priorityClassName: priorityClassName } } } },
        '#withTolerations':: d.fn(help="\"Proxy Pod's tolerations.\\nBy default Tailscale Kubernetes operator does not apply any\\ntolerations.\\nhttps://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling\"", args=[d.arg(name='tolerations', type=d.T.array)]),
        withTolerations(tolerations): { spec+: { statefulSet+: { pod+: { tolerations: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } },
        '#withTolerationsMixin':: d.fn(help="\"Proxy Pod's tolerations.\\nBy default Tailscale Kubernetes operator does not apply any\\ntolerations.\\nhttps://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#scheduling\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='tolerations', type=d.T.array)]),
        withTolerationsMixin(tolerations): { spec+: { statefulSet+: { pod+: { tolerations+: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } },
        '#withTopologySpreadConstraints':: d.fn(help="\"Proxy Pod's topology spread constraints.\\nBy default Tailscale Kubernetes operator does not apply any topology spread constraints.\\nhttps://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/\"", args=[d.arg(name='topologySpreadConstraints', type=d.T.array)]),
        withTopologySpreadConstraints(topologySpreadConstraints): { spec+: { statefulSet+: { pod+: { topologySpreadConstraints: if std.isArray(v=topologySpreadConstraints) then topologySpreadConstraints else [topologySpreadConstraints] } } } },
        '#withTopologySpreadConstraintsMixin':: d.fn(help="\"Proxy Pod's topology spread constraints.\\nBy default Tailscale Kubernetes operator does not apply any topology spread constraints.\\nhttps://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='topologySpreadConstraints', type=d.T.array)]),
        withTopologySpreadConstraintsMixin(topologySpreadConstraints): { spec+: { statefulSet+: { pod+: { topologySpreadConstraints+: if std.isArray(v=topologySpreadConstraints) then topologySpreadConstraints else [topologySpreadConstraints] } } } },
      },
      '#withAnnotations':: d.fn(help='"Annotations that will be added to the StatefulSet created for the proxy.\\nAny Annotations specified here will be merged with the default annotations\\napplied to the StatefulSet by the Tailscale Kubernetes operator as\\nwell as any other annotations that might have been applied by other\\nactors.\\nAnnotations must be valid Kubernetes annotations.\\nhttps://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/#syntax-and-character-set"', args=[d.arg(name='annotations', type=d.T.object)]),
      withAnnotations(annotations): { spec+: { statefulSet+: { annotations: annotations } } },
      '#withAnnotationsMixin':: d.fn(help='"Annotations that will be added to the StatefulSet created for the proxy.\\nAny Annotations specified here will be merged with the default annotations\\napplied to the StatefulSet by the Tailscale Kubernetes operator as\\nwell as any other annotations that might have been applied by other\\nactors.\\nAnnotations must be valid Kubernetes annotations.\\nhttps://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/#syntax-and-character-set"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
      withAnnotationsMixin(annotations): { spec+: { statefulSet+: { annotations+: annotations } } },
      '#withLabels':: d.fn(help='"Labels that will be added to the StatefulSet created for the proxy.\\nAny labels specified here will be merged with the default labels\\napplied to the StatefulSet by the Tailscale Kubernetes operator as\\nwell as any other labels that might have been applied by other\\nactors.\\nLabel keys and values must be valid Kubernetes label keys and values.\\nhttps://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#syntax-and-character-set"', args=[d.arg(name='labels', type=d.T.object)]),
      withLabels(labels): { spec+: { statefulSet+: { labels: labels } } },
      '#withLabelsMixin':: d.fn(help='"Labels that will be added to the StatefulSet created for the proxy.\\nAny labels specified here will be merged with the default labels\\napplied to the StatefulSet by the Tailscale Kubernetes operator as\\nwell as any other labels that might have been applied by other\\nactors.\\nLabel keys and values must be valid Kubernetes label keys and values.\\nhttps://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#syntax-and-character-set"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
      withLabelsMixin(labels): { spec+: { statefulSet+: { labels+: labels } } },
    },
    '#staticEndpoints':: d.obj(help="\"Configuration for 'static endpoints' on proxies in order to facilitate\\ndirect connections from other devices on the tailnet.\\nSee https://tailscale.com/kb/1445/kubernetes-operator-customization#static-endpoints.\""),
    staticEndpoints: {
      '#nodePort':: d.obj(help='"The configuration for static endpoints using NodePort Services."'),
      nodePort: {
        '#ports':: d.obj(help="\"The port ranges from which the operator will select NodePorts for the Services.\\nYou must ensure that firewall rules allow UDP ingress traffic for these ports\\nto the node's external IPs.\\nThe ports must be in the range of service node ports for the cluster (default `30000-32767`).\\nSee https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport.\""),
        ports: {
          '#withEndPort':: d.fn(help='"endPort indicates that the range of ports from port to endPort if set, inclusive,\\nshould be used. This field cannot be defined if the port field is not defined.\\nThe endPort must be either unset, or equal or greater than port."', args=[d.arg(name='endPort', type=d.T.integer)]),
          withEndPort(endPort): { endPort: endPort },
          '#withPort':: d.fn(help='"port represents a port selected to be used. This is a required field."', args=[d.arg(name='port', type=d.T.integer)]),
          withPort(port): { port: port },
        },
        '#withPorts':: d.fn(help="\"The port ranges from which the operator will select NodePorts for the Services.\\nYou must ensure that firewall rules allow UDP ingress traffic for these ports\\nto the node's external IPs.\\nThe ports must be in the range of service node ports for the cluster (default `30000-32767`).\\nSee https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport.\"", args=[d.arg(name='ports', type=d.T.array)]),
        withPorts(ports): { spec+: { staticEndpoints+: { nodePort+: { ports: if std.isArray(v=ports) then ports else [ports] } } } },
        '#withPortsMixin':: d.fn(help="\"The port ranges from which the operator will select NodePorts for the Services.\\nYou must ensure that firewall rules allow UDP ingress traffic for these ports\\nto the node's external IPs.\\nThe ports must be in the range of service node ports for the cluster (default `30000-32767`).\\nSee https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='ports', type=d.T.array)]),
        withPortsMixin(ports): { spec+: { staticEndpoints+: { nodePort+: { ports+: if std.isArray(v=ports) then ports else [ports] } } } },
        '#withSelector':: d.fn(help="\"A selector which will be used to select the node's that will have their `ExternalIP`'s advertised\\nby the ProxyGroup as Static Endpoints.\"", args=[d.arg(name='selector', type=d.T.object)]),
        withSelector(selector): { spec+: { staticEndpoints+: { nodePort+: { selector: selector } } } },
        '#withSelectorMixin':: d.fn(help="\"A selector which will be used to select the node's that will have their `ExternalIP`'s advertised\\nby the ProxyGroup as Static Endpoints.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='selector', type=d.T.object)]),
        withSelectorMixin(selector): { spec+: { staticEndpoints+: { nodePort+: { selector+: selector } } } },
      },
    },
    '#tailscale':: d.obj(help='"TailscaleConfig contains options to configure the tailscale-specific\\nparameters of proxies."'),
    tailscale: {
      '#withAcceptRoutes':: d.fn(help='"AcceptRoutes can be set to true to make the proxy instance accept\\nroutes advertized by other nodes on the tailnet, such as subnet\\nroutes.\\nThis is equivalent of passing --accept-routes flag to a tailscale Linux client.\\nhttps://tailscale.com/kb/1019/subnets#use-your-subnet-routes-from-other-devices\\nDefaults to false."', args=[d.arg(name='acceptRoutes', type=d.T.boolean)]),
      withAcceptRoutes(acceptRoutes): { spec+: { tailscale+: { acceptRoutes: acceptRoutes } } },
    },
    '#withUseLetsEncryptStagingEnvironment':: d.fn(help="\"Set UseLetsEncryptStagingEnvironment to true to issue TLS\\ncertificates for any HTTPS endpoints exposed to the tailnet from\\nLetsEncrypt's staging environment.\\nhttps://letsencrypt.org/docs/staging-environment/\\nThis setting only affects Tailscale Ingress resources.\\nBy default Ingress TLS certificates are issued from LetsEncrypt's\\nproduction environment.\\nChanging this setting true -\u003e false, will result in any\\nexisting certs being re-issued from the production environment.\\nChanging this setting false (default) -\u003e true, when certs have already\\nbeen provisioned from production environment will NOT result in certs\\nbeing re-issued from the staging environment before they need to be\\nrenewed.\"", args=[d.arg(name='useLetsEncryptStagingEnvironment', type=d.T.boolean)]),
    withUseLetsEncryptStagingEnvironment(useLetsEncryptStagingEnvironment): { spec+: { useLetsEncryptStagingEnvironment: useLetsEncryptStagingEnvironment } },
  },
  '#mixin': 'ignore',
  mixin: self,
}
